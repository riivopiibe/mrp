name: Run Sitemap Scraper

on:
  #schedule:
  #  - cron: "0 5 * * *"  # Run at 5:00 AM every day (UTC time)
  workflow_dispatch:       # Allow manual runs

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # Decrypt and write the credentials.json file
      - name: Create credentials.json
        run: |
          echo "${{ secrets.CREDENTIALS_JSON }}" | sed 's/\\n/\/g' > credentials.json

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 gspread oauth2client lxml

      - name: Run Scraper
        env:
          GOOGLE_APPLICATION_CREDENTIALS: credentials.json
        run: python refresh_products.py
